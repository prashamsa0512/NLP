{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNecO0o1gKX5LkOb39GySyM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashamsa0512/NLP/blob/main/assignment%2010.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFb-r-yxGcWV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Latent space parameters\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_var = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, input_dim),\n",
        "            nn.Sigmoid()  # For MNIST images (values between 0 and 1)\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        return self.fc_mu(h), self.fc_var(h)\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encode(x.view(-1, 784))\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        return self.decode(z), mu, log_var\n",
        "\n",
        "def train_vae(model, train_loader, num_epochs=50, learning_rate=1e-3, device='cuda'):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        recon_loss_total = 0\n",
        "        kl_loss_total = 0\n",
        "\n",
        "        for batch_idx, (data, _) in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            recon_batch, mu, log_var = model(data)\n",
        "\n",
        "            # Reconstruction loss (binary cross entropy)\n",
        "            recon_loss = nn.functional.binary_cross_entropy(\n",
        "                recon_batch, data.view(-1, 784), reduction='sum')\n",
        "\n",
        "            # KL divergence loss\n",
        "            kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "\n",
        "            # Total loss\n",
        "            loss = recon_loss + kl_loss\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            recon_loss_total += recon_loss.item()\n",
        "            kl_loss_total += kl_loss.item()\n",
        "\n",
        "        # Print epoch statistics\n",
        "        avg_loss = total_loss / len(train_loader.dataset)\n",
        "        avg_recon_loss = recon_loss_total / len(train_loader.dataset)\n",
        "        avg_kl_loss = kl_loss_total / len(train_loader.dataset)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "            print(f'Average Loss: {avg_loss:.4f}')\n",
        "            print(f'Reconstruction Loss: {avg_recon_loss:.4f}')\n",
        "            print(f'KL Loss: {avg_kl_loss:.4f}\\n')\n",
        "\n",
        "def visualize_results(model, test_loader, device='cuda'):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Get a batch of test data\n",
        "        data, _ = next(iter(test_loader))\n",
        "        data = data.to(device)\n",
        "\n",
        "        # Reconstruct images\n",
        "        recon_batch, _, _ = model(data)\n",
        "\n",
        "        # Generate new images from random latent vectors\n",
        "        z = torch.randn(8, 20).to(device)\n",
        "        generated = model.decode(z)\n",
        "\n",
        "        # Plot results\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Original images\n",
        "        for i in range(8):\n",
        "            plt.subplot(3, 8, i + 1)\n",
        "            plt.imshow(data[i].cpu().numpy().reshape(28, 28), cmap='gray')\n",
        "            plt.axis('off')\n",
        "            if i == 0:\n",
        "                plt.title('Original')\n",
        "\n",
        "        # Reconstructed images\n",
        "        for i in range(8):\n",
        "            plt.subplot(3, 8, i + 9)\n",
        "            plt.imshow(recon_batch[i].cpu().numpy().reshape(28, 28), cmap='gray')\n",
        "            plt.axis('off')\n",
        "            if i == 0:\n",
        "                plt.title('Reconstructed')\n",
        "\n",
        "        # Generated images\n",
        "        for i in range(8):\n",
        "            plt.subplot(3, 8, i + 17)\n",
        "            plt.imshow(generated[i].cpu().numpy().reshape(28, 28), cmap='gray')\n",
        "            plt.axis('off')\n",
        "            if i == 0:\n",
        "                plt.title('Generated')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def main():\n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load MNIST dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    train_dataset = torchvision.datasets.MNIST(\n",
        "        root='./data', train=True, transform=transform, download=True)\n",
        "    test_dataset = torchvision.datasets.MNIST(\n",
        "        root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "    # Initialize model\n",
        "    model = VAE().to(device)\n",
        "\n",
        "    # Train the model\n",
        "    train_vae(model, train_loader, device=device)\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_results(model, test_loader, device=device)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}